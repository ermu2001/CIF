{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nanahoshi/school/dl-2024-mp\n"
     ]
    }
   ],
   "source": [
    "%cd ~/school/dl-2024-mp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nanahoshi/bin/miniconda3/envs/joamama/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cifnet-18-tiny-lr0.01-bottleneck',\n",
       " 'cifnet-18-apple--lr0.001--tbtest',\n",
       " 'cifnet-18-cucumber-nope--lr0.001--d4_256',\n",
       " 'cifnet-18-tiny-lr0.01-attention',\n",
       " 'cifnet-18-tiny_attention--lr0.001--prenorm',\n",
       " 'cifnet-18-banana--lr0.001--sigmoid_4d_128-128-64-64',\n",
       " 'cifnet-18-cucumber--lr0.001--d4_256',\n",
       " 'cifnet-18-tiny-lr0.1-baseline']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "models = os.listdir('OUTPUTS')\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'data': array([[133, 136, 136, ..., 226, 225, 224],\n",
       "        [160, 177, 176, ...,  89,  89,  88],\n",
       "        [255, 255, 255, ..., 211, 213, 215],\n",
       "        ...,\n",
       "        [ 29,  29,  45, ..., 156, 155, 154],\n",
       "        [124, 123, 126, ...,  49,  49,  51],\n",
       "        [255, 255, 255, ..., 250, 251, 255]], dtype=uint8),\n",
       " b'ids': array([   0,    1,    2, ..., 9997, 9998, 9999])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_test_nolabels = unpickle('explore/cifar_test_nolabels.pkl')\n",
    "cifar_test_nolabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS/cifnet-18-cucumber--lr0.001--d4_256\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from transformers import AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "from models.cifnet import (\n",
    "    CifNetForImageClassification,\n",
    "    CifNetConfig,\n",
    ")\n",
    "\n",
    "def setup_model(model_name_or_path, ):\n",
    "    model_config = CifNetConfig.from_pretrained(model_name_or_path)\n",
    "    # model = CifNetForImageClassification(model_config)\n",
    "    model = CifNetForImageClassification.from_pretrained(model_name_or_path, config=model_config)\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name_or_path)\n",
    "    return model, processor\n",
    "\n",
    "model_path = os.path.join('OUTPUTS', models[6])\n",
    "print(model_path)\n",
    "# model, image_processor = setup_model('OUTPUTS/cifnet-18-cucumber--lr0.001--d4_256', )\n",
    "model, image_processor = setup_model(model_path)\n",
    "\n",
    "# If using a GPU\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import PIL.Image\n",
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, samples, transform):\n",
    "        self.samples = samples\n",
    "        self.trasnform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        sample = sample.reshape((3, 32, 32)).transpose(1, 2, 0)\n",
    "        sample = PIL.Image.fromarray(sample)\n",
    "        sample.save('test.jpg')\n",
    "        sample = self.trasnform(sample)\n",
    "        return{\n",
    "            \"pixel_values\": sample,\n",
    "            \"index\": torch.Tensor([index]),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the datasets\n",
    "\n",
    "# Define torchvision transforms to be applied to each image.\n",
    "if \"shortest_edge\" in image_processor.size:\n",
    "  size = image_processor.size[\"shortest_edge\"]\n",
    "else:\n",
    "  size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "normalize = (\n",
    "  Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "  if hasattr(image_processor, \"image_mean\") and hasattr(image_processor, \"image_std\")\n",
    "  else Lambda(lambda x: x)\n",
    ")\n",
    "# train_transforms = Compose(\n",
    "#   [\n",
    "#     RandomResizedCrop(size),\n",
    "#     RandomHorizontalFlip(),\n",
    "#     ToTensor(),\n",
    "#     normalize,\n",
    "#   ]\n",
    "# )\n",
    "# val_transforms = Compose(\n",
    "#   [\n",
    "#     Resize(size),\n",
    "#     CenterCrop(size),\n",
    "#     ToTensor(),\n",
    "#     normalize,\n",
    "#   ]\n",
    "# )\n",
    "# dataset_name = \"explore/cifar_test_nolabels.csv\"\n",
    "# dataset = load_dataset(dataset_name)\n",
    "# max_train_samples = 1000\n",
    "seed = 42\n",
    "val_transforms = Compose(\n",
    "  [\n",
    "    Resize(size),\n",
    "    CenterCrop(size),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "  ]\n",
    ")\n",
    "\n",
    "# # Set the validation transforms\n",
    "# test_dataset = dataset\n",
    "per_device_test_batch_size = 4\n",
    "num_workers = 4\n",
    "test_dataset = EvalDataset(cifar_test_nolabels[b'data'], val_transforms)\n",
    "# DataLoaders creation:\n",
    "def collate_fn(examples):\n",
    "  pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "  indexs = torch.stack([example[\"index\"] for example in examples])\n",
    "  # labels = torch.tensor([example[label_column_name] for example in examples])\n",
    "  # return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "  return {\n",
    "    \"pixel_values\": pixel_values,\n",
    "    \"indexs\": indexs\n",
    "  }\n",
    "\n",
    "# test_dataloader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=per_device_test_batch_size, num_workers=num_workers,)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=per_device_test_batch_size, num_workers=num_workers, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:16<00:00, 155.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessed_test_data = preprocessed_test_data.to('cuda')\n",
    "\n",
    "ID_list = []\n",
    "label_list = []\n",
    "from tqdm import tqdm\n",
    "for batch in tqdm(test_dataloader):\n",
    "    pixel_values = batch['pixel_values'].to(model.device)\n",
    "    indexs = batch['indexs'].flatten().int().tolist()\n",
    "    # print(indexs)\n",
    "    # print(pixel_values)\n",
    "    outputs = model(pixel_values)\n",
    "    logits = outputs.logits\n",
    "    labels = torch.argmax(logits, dim=-1).flatten().int().tolist()\n",
    "    # print(labels)\n",
    "    # print(indexs)\n",
    "    ID_list.extend(indexs)\n",
    "    label_list.extend(labels)\n",
    "    # break\n",
    "\n",
    "# Make predictions\n",
    "# with torch.no_grad():\n",
    "    # predictions = model(preprocessed_test_data)\n",
    "\n",
    "# Process predictions as needed (e.g., applying softmax to get probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "import pandas as pd\n",
    "\n",
    "# ID,Labels\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "df = pd.DataFrame({\n",
    "    'ID': ID_list,\n",
    "    'Labels': label_list\n",
    "})\n",
    "\n",
    "df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels\n",
       "3    1124\n",
       "9    1078\n",
       "7    1042\n",
       "8    1024\n",
       "1    1007\n",
       "6     987\n",
       "5     957\n",
       "4     951\n",
       "0     925\n",
       "2     905\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the predictions distribution\n",
    "df.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign correct labels for each 1 thousand samples, the correct labels are the first 1 thousand labels are in the order of 8 2 9 0 4 3 6 1 7 5\n",
    "correct_labels = [8, 2, 9, 0, 4, 3, 6, 1, 7, 5]\n",
    "\n",
    "for i in range(10):\n",
    "    df.loc[df['ID'].between(i*1000, (i+1)*1000), 'C_Labels'] = correct_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy of the model\n",
    "(df['Labels'] == df['C_Labels']).sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "cm = confusion_matrix(df['C_Labels'], df['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[758,  23,  29,  21,   2,   9,  12,  16,  79,  51],\n",
       "       [ 25, 778,   5,   7,   0,   3,   4,   4,  15, 159],\n",
       "       [ 33,   2, 775,  50,  43,  22,  42,  21,   4,   8],\n",
       "       [ 13,   0,  19, 808,  10,  96,  23,  16,   7,   8],\n",
       "       [ 15,   2,  17,  38, 827,  22,  27,  40,  10,   2],\n",
       "       [  4,   4,  16, 113,  16, 774,  22,  32,  12,   7],\n",
       "       [ 18,   5,  34,  50,  14,  12, 851,   9,   3,   4],\n",
       "       [  5,   2,   4,  26,  35,  18,   3, 893,   6,   8],\n",
       "       [ 45,  15,   5,   9,   3,   0,   3,  10, 882,  28],\n",
       "       [  9, 176,   1,   2,   1,   1,   0,   1,   6, 803]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joamama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
